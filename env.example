# PromptQL Latency Testing Suite Configuration
# Copy this file to .env and fill in your actual values

# ============================================
# DEVELOPMENT ENVIRONMENT
# ============================================

# PromptQL Configuration for Dev
PROMPTQL_API_KEY_DEV="your-dev-api-key"
PROMPTQL_DATA_PLANE_URL_DEV="https://promptql.dev.private-ddn.hasura.app/api/query"

# DDN Configuration for Dev
DDN_URL_DEV="https://app-dev.private-ddn.hasura.app/v1/sql"
DDN_AUTH_TOKEN_DEV="your-dev-ddn-auth-token"

# Hasura PAT for Dev
HASURA_PAT_DEV="your-dev-hasura-pat"

# ============================================
# STAGING ENVIRONMENT
# ============================================

# PromptQL Configuration for Staging
PROMPTQL_API_KEY_STAGING="your-staging-api-key"
PROMPTQL_DATA_PLANE_URL_STAGING="https://promptql.staging.private-ddn.hasura.app/api/query"

# DDN Configuration for Staging
DDN_URL_STAGING="https://app-staging.private-ddn.hasura.app/v1/sql"
DDN_AUTH_TOKEN_STAGING="your-staging-ddn-auth-token"

# Hasura PAT for Staging
HASURA_PAT_STAGING="your-staging-hasura-pat"

# ============================================
# PRODUCTION ENVIRONMENT
# ============================================

# PromptQL Configuration for Production
PROMPTQL_API_KEY_PRODUCTION="your-production-api-key"
PROMPTQL_DATA_PLANE_URL_PRODUCTION="https://promptql.production.private-ddn.hasura.app/api/query"

# DDN Configuration for Production
DDN_URL_PRODUCTION="https://app-production.private-ddn.hasura.app/v1/sql"
DDN_AUTH_TOKEN_PRODUCTION="your-production-ddn-auth-token"

# Hasura PAT for Production
HASURA_PAT_PRODUCTION="your-production-hasura-pat"

# ============================================
# LLM CONFIGURATION (Optional)
# ============================================
# Specify the LLM provider and model to use
# Both provider and model must be set for custom LLM configuration
# If not provided, defaults to: anthropic/claude-sonnet-4-20250514

# Development
# SPECIFIC_LLM_PROVIDER_DEV="openai"
# SPECIFIC_LLM_MODEL_DEV="gpt-4"

# Staging
# SPECIFIC_LLM_PROVIDER_STAGING="openai"
# SPECIFIC_LLM_MODEL_STAGING="gpt-4"

# Production
# SPECIFIC_LLM_PROVIDER_PRODUCTION="anthropic"
# SPECIFIC_LLM_MODEL_PRODUCTION="claude-3-opus-20240229"

# Default (when no environment variables are set):
# Provider: anthropic
# Model: claude-sonnet-4-20250514

# Example providers and models:
# - openai: gpt-4, gpt-4-turbo-preview, gpt-3.5-turbo
# - anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-sonnet-4-20250514
# - azure: gpt-4, gpt-35-turbo
# - cohere: command, command-light

# ============================================
# PATRONUS CONFIGURATION (Optional)
# ============================================
# These are shared across all environments
# If not provided, the script will run latency tests only

# PATRONUS_BASE_URL="patronus-backend.internal.example.com"
# PATRONUS_API_KEY="your-patronus-api-key"
# PATRONUS_PROJECT_ID="your-patronus-project-id"

# ============================================
# DATABASE CONFIGURATION (Optional)
# ============================================
# Specifies the database type for query ID extraction from spans
# If set to "redshift", will look for "redshift.query_id" in span attributes
# If not set or empty, will look for ".query_id" in span attributes

DATABASE="redshift"